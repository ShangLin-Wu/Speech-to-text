{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "「Speech To Text.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShangLin-Wu/Speech-to-text/blob/main/%E3%80%8CSpeech_To_Text_version2-2_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdqM73Ibh8Mp"
      },
      "source": [
        "# mp3 to text with deep speech model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrH9g0n1hzpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d81e5fb-6675-49dd-bf8e-56dc45647fb2"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import shlex\n",
        "import subprocess\n",
        "import sys\n",
        "import wave\n",
        "\n",
        "!pip install deepspeech \n",
        "from deepspeech import Model, version\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# audio converters\n",
        "!apt update && apt-get install ffmpeg mpg123\n",
        "\n",
        "# sox package for adjusting sample rate.\n",
        "!apt-get install libsox-fmt-all libsox-dev sox\n",
        "\n",
        "# neural network model for acoustic recognition\n",
        "# !wget -O - https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/models_0.9.tar.gz | tar xvfz -"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepspeech in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from deepspeech) (1.19.5)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 256 kB in 2s (139 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "mpg123 is already the newest version (1.25.10-1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsox-dev is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "libsox-fmt-all is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "sox is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr-SPvuT_nEF"
      },
      "source": [
        "# Accoustic parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQFywq8DlIbv"
      },
      "source": [
        "model    = '/content/models/deepspeech-0.9.3-models.pbmm'\n",
        "scorer = '/content/models/deepspeech-0.9.3-models.scorer'\n",
        "\n",
        "# These constants control the beam search decoder\n",
        "\n",
        "# Beam width used in the CTC decoder when building candidate transcriptions\n",
        "BEAM_WIDTH = 100\n",
        "\n",
        "# The alpha hyperparameter of the CTC decoder. Language Model weight\n",
        "LM_WEIGHT = 0.76\n",
        "\n",
        "# Valid word insertion weight. This is used to lessen the word insertion penalty\n",
        "# when the inserted word is part of the vocabulary\n",
        "VALID_WORD_COUNT_WEIGHT = 1.8\n",
        "\n",
        "\n",
        "# These constants are tied to the shape of the graph used (changing them changes\n",
        "# the geometry of the first layer), so make sure you use the same constants that\n",
        "# were used during training\n",
        "\n",
        "# Number of MFCC features to use\n",
        "# N_FEATURES = 32\n",
        "\n",
        "# Size of the context window used for producing timesteps in the input vector\n",
        "# N_CONTEXT = 12"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDlyOTMU_um-"
      },
      "source": [
        "# Adapt Sample Rate of Audio File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5kgGTzlNop"
      },
      "source": [
        "def convert_samplerate(audio_path):\n",
        "    sox_cmd = 'sox {} --type raw --bits 16 --channels 1 --rate 16000 --encoding signed-integer --endian little --compression 0.0 --no-dither - '.format(audio_path)\n",
        "    try:\n",
        "        output = subprocess.check_output(shlex.split(sox_cmd), stderr=subprocess.PIPE)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError('SoX returned non-zero status: {}'.format(e.stderr))\n",
        "    except OSError as e:\n",
        "        raise OSError(e.errno, 'SoX not found, use 16kHz files or install it: {}'.format(e.strerror))\n",
        "\n",
        "    return 16000, np.frombuffer(output, np.int16)\n",
        "\n"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6WuuR5S_5tu"
      },
      "source": [
        "# Input MP3 Audio File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byQfXtXLqD-A"
      },
      "source": [
        "# upload mp3 audio file.\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for audio in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#          name=audio, length=len(uploaded[audio])))\n",
        "\n",
        "# os.rename(audio, 'speech.mp3')\n",
        "# audio = 'speech.wav'\n",
        "\n",
        "# convert to wav file.  \n",
        "# !ffmpeg -i speech.mp3 -vn -acodec pcm_s16le -ac 1 -ar 16000 -f wav speech.wav\n",
        "# !mpg123 -w speech.wav speech.mp3"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI1ufWC4AAsq"
      },
      "source": [
        "# Convert MP3 to Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aubQx7CilQGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5179d9-dbeb-4b09-fd7c-75edf98b9941"
      },
      "source": [
        "    audio = 'speech.wav'   \n",
        "    \n",
        "    print('Loading model from file {}'.format(model), file=sys.stderr)\n",
        "    model_load_start = timer()\n",
        "    ds = Model(model)\n",
        "    model_load_end = timer() - model_load_start\n",
        "    print('Loaded model in {:.3}s.'.format(model_load_end), file=sys.stderr)\n",
        "\n",
        "    lm_load_start = timer()\n",
        "    ds.setBeamWidth(BEAM_WIDTH)\n",
        "    ds.enableExternalScorer(scorer)\n",
        "    ds.setScorerAlphaBeta(LM_WEIGHT,VALID_WORD_COUNT_WEIGHT)\n",
        "    lm_load_end = timer() - lm_load_start\n",
        "        \n",
        "    fin = wave.open(audio, 'rb')\n",
        "    fs = fin.getframerate()\n",
        "\n",
        "    if fs != 16000:\n",
        "        print('Warning: original sample rate ({}) is different than 16kHz. Resampling might produce erratic speech recognition.'.format(fs), file=sys.stderr)\n",
        "        fs, audio = convert_samplerate(audio)\n",
        "    else:\n",
        "        bf = fin.readframes(fin.getnframes())\n",
        "        audio = np.frombuffer(bf, np.int16)\n",
        "\n",
        "    audio_length = fin.getnframes() * (1/16000)\n",
        "    fin.close()\n",
        "\n",
        "    print('Running inference.', file=sys.stderr)\n",
        "    print('================================\\n')\n",
        "    inference_start = timer()\n",
        "    print(ds.stt(audio))\n",
        "    inference_end = timer() - inference_start\n",
        "    print('\\n================================')\n",
        "    print('Inference took %0.3fs for %0.3fs audio file.' % (inference_end, audio_length), file=sys.stderr)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file /content/models/deepspeech-0.9.3-models.pbmm\n",
            "Loaded model in 0.00977s.\n",
            "Running inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\n",
            "\n",
            "she fantasies about traveling through the regions archeological sights and picturesque town ever since she was a teenager growing up in finland poring over travel brochures and daydreaming about future adventures\n",
            "\n",
            "================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inference took 7.952s for 12.696s audio file.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0QCJMqkaq_v"
      },
      "source": [
        "# She'd fantasized about traveling through the region's archaeological sites and picturesque towns ever since she was a teenager growing up in Finland, poring over travel brochures and daydreaming about future adventures."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vFVCw_86H00"
      },
      "source": [
        "# Beam width used in the CTC decoder when building candidate transcriptions\n",
        "BEAM_WIDTH = 100\n",
        "\n",
        "# The alpha hyperparameter of the CTC decoder. Language Model weight\n",
        "LM_WEIGHT = 0.76\n",
        "\n",
        "# Valid word insertion weight. This is used to lessen the word insertion penalty\n",
        "# when the inserted word is part of the vocabulary\n",
        "VALID_WORD_COUNT_WEIGHT = 1.8\n",
        "\n",
        "# she fantasies about traveling through the regions archeological sights and picturesque town ever since she was a teenager growing up in finland poring over travel brochures and daydreaming about future adventures\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}